{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>freq</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>group,</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>of</td>\n",
       "      <td>176</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     word  freq\n",
       "0  group,    31\n",
       "1      of   176"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "df_low_freq_words = pd.read_csv(\"all_words_freq_sender.csv\")\n",
    "df_low_freq_words.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>freq</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>management</td>\n",
       "      <td>422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>claims</td>\n",
       "      <td>411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>inc.</td>\n",
       "      <td>408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>services,</td>\n",
       "      <td>395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>272</th>\n",
       "      <td>box</td>\n",
       "      <td>353</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           word  freq\n",
       "48   management   422\n",
       "49       claims   411\n",
       "47         inc.   408\n",
       "21    services,   395\n",
       "272         box   353"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_low_freq_words = df_low_freq_words.sort_values([\"freq\"], ascending=[False])\n",
    "df_low_freq_words.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "367"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "low_weightage_words = list(df_low_freq_words[df_low_freq_words[\"freq\"]>3][\"word\"])\n",
    "len(low_weightage_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word2ngrams(text, n=3):\n",
    "  \"\"\" Convert word into character ngrams. \"\"\"\n",
    "  return set([text[i:i+n] for i in range(len(text)-n+1)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_functional_metrics(gt,pred):\n",
    "\n",
    "    #remove extra spaces in bw words\n",
    "    gt = re.sub(' +', ' ', gt)\n",
    "    pred = re.sub(' +', ' ', pred)\n",
    "    \n",
    "    ## remove low- weightaged words from both GT and pred\n",
    "    gt_words = gt.lower().split(' ')\n",
    "    pred_words = pred.lower().split(' ')\n",
    "\n",
    "    norm_gt_words = []\n",
    "    for word in gt_words:\n",
    "        if word not in low_weightage_words:\n",
    "            norm_gt_words.append(word)\n",
    "    norm_gt = ' '.join(norm_gt_words)  \n",
    "\n",
    "    norm_pred_words = []\n",
    "    for word in pred_words:\n",
    "        if word not in low_weightage_words:\n",
    "            norm_pred_words.append(word)\n",
    "    norm_pred = ' '.join(norm_pred_words)\n",
    "\n",
    "    print(\"norm gt, norm pred : \", norm_gt,\"\\n\", norm_pred)\n",
    "\n",
    "    # get n-grams for both GT and Pred, and find the precision and recall bw them\n",
    "    len_norm_gt, len_norm_pred = len(norm_gt), len(norm_pred)\n",
    "    max_ngrams = (min(len_norm_gt,len_norm_pred)) # -1/2 ??\n",
    "    weighted_f1_score_num = 0\n",
    "\n",
    "    for i in range(2, max_ngrams+1):\n",
    "        gt_igrams = word2ngrams(norm_gt, n=i)\n",
    "        pred_igrams = word2ngrams(norm_pred, n=i)\n",
    "\n",
    "        n_common_elements = len(gt_igrams) - (len(gt_igrams.difference(pred_igrams)))\n",
    "        # print(\"n_common_elements : \", n_common_elements)\n",
    "        precision = n_common_elements/len(pred_igrams)\n",
    "        recall = n_common_elements/len(gt_igrams)\n",
    "\n",
    "        # print(f\"precision and recall at {i} is {precision} and {recall}\")\n",
    "        i_f1_score = 2*precision*recall / (precision+recall)\n",
    "        weighted_f1_score_num += ((i/max_ngrams)*i_f1_score)\n",
    "        # print(\"i ((i/max_ngrams)*fp) : \", i, ((i/max_ngrams)*i_f1_score), i_f1_score)\n",
    "\n",
    "    weighted_f1_score_denom = (max_ngrams+1)/2 - (1/max_ngrams)\n",
    "    print(\"weighted_f1_score_denom : \", weighted_f1_score_denom)\n",
    "    return weighted_f1_score_num/weighted_f1_score_denom\n",
    "\n",
    "\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gt pred :  ['edwin', 'k.', 'stone', 'attorney', 'at', 'law'] ['edwin', 'k.']\n",
      "norm gt, norm pred :  edwin stone \n",
      " edwin\n",
      "n_common_elements :  4\n",
      "precision and recall at 2 is 1.0 and 0.4\n",
      "i ((i/max_ngrams)*fp) :  2 0.22857142857142862 0.5714285714285715\n",
      "n_common_elements :  3\n",
      "precision and recall at 3 is 1.0 and 0.3333333333333333\n",
      "i ((i/max_ngrams)*fp) :  3 0.3 0.5\n",
      "n_common_elements :  2\n",
      "precision and recall at 4 is 1.0 and 0.25\n",
      "i ((i/max_ngrams)*fp) :  4 0.32000000000000006 0.4\n",
      "n_common_elements :  1\n",
      "precision and recall at 5 is 1.0 and 0.14285714285714285\n",
      "i ((i/max_ngrams)*fp) :  5 0.25 0.25\n",
      "weighted_f1_score_denom :  2.8\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.3923469387755103"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "gt = \"Edwin K. Stone Attorney at Law\"\n",
    "pred = \"Edwin K.\"\n",
    "\n",
    "get_functional_metrics(gt,pred)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
